"""
ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ
"""

import ccxt
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import json
import logging
from typing import Dict, List, Optional, Tuple
import asyncio
import aiohttp
import time

logger = logging.getLogger(__name__)

class DataManager:
    """ì‹¤ì œ ì‹œì¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ê´€ë¦¬"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.exchange = None
        self.symbol_cache = {}
        self.price_cache = {}
        self.cache_ttl = 300  # 5ë¶„ ìºì‹œ
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(data_dir, exist_ok=True)
        os.makedirs(f"{data_dir}/raw", exist_ok=True)
        os.makedirs(f"{data_dir}/processed", exist_ok=True)
        
        self.init_exchange()
    
    def init_exchange(self):
        """ë°”ì´ë‚¸ìŠ¤ ê±°ë˜ì†Œ ì´ˆê¸°í™”"""
        try:
            self.exchange = ccxt.binance({
                'apiKey': os.getenv('BINANCE_API_KEY'),
                'secret': os.getenv('BINANCE_SECRET_KEY'),
                'timeout': 30000,
                'enableRateLimit': True,
                'options': {
                    'defaultType': 'future',  # ì„ ë¬¼ ê±°ë˜
                }
            })
            logger.info("ë°”ì´ë‚¸ìŠ¤ ê±°ë˜ì†Œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë°”ì´ë‚¸ìŠ¤ ê±°ë˜ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ìƒŒë“œë°•ìŠ¤ ëª¨ë“œë¡œ ì´ˆê¸°í™”
            self.exchange = ccxt.binance({
                'sandbox': True,
                'enableRateLimit': True,
                'options': {
                    'defaultType': 'future',
                }
            })
    
    async def download_historical_data(
        self, 
        symbol: str, 
        timeframe: str = '1h',
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        limit: int = 1000
    ) -> pd.DataFrame:
        """
        ì‹¤ì œ íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        
        Args:
            symbol: ê±°ë˜ ì‹¬ë³¼ (ì˜ˆ: 'BTC/USDT')
            timeframe: ì‹œê°„í”„ë ˆì„ ('1m', '5m', '15m', '1h', '4h', '1d')
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            limit: ìµœëŒ€ ìº”ë“¤ ìˆ˜
            
        Returns:
            DataFrame: OHLCV ë°ì´í„°
        """
        try:
            # ìºì‹œ í™•ì¸
            cache_key = f"{symbol}_{timeframe}_{start_date}_{end_date}"
            if cache_key in self.price_cache:
                cache_time, data = self.price_cache[cache_key]
                if time.time() - cache_time < self.cache_ttl:
                    logger.info(f"ìºì‹œëœ ë°ì´í„° ë°˜í™˜: {symbol}")
                    return data
            
            # ì‹¬ë³¼ ì •ê·œí™”
            if '/' not in symbol:
                symbol = symbol.replace('USDT', '/USDT')
            
            # ê¸°ë³¸ ë‚ ì§œ ì„¤ì •
            if not end_date:
                end_date = datetime.now()
            if not start_date:
                start_date = end_date - timedelta(days=30)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
            since = int(start_date.timestamp() * 1000)
            until = int(end_date.timestamp() * 1000)
            
            logger.info(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘: {symbol} ({timeframe})")
            
            all_candles = []
            current_since = since
            
            while current_since < until:
                try:
                    # ë°”ì´ë‚¸ìŠ¤ API í˜¸ì¶œ
                    ohlcv = await self.exchange.fetch_ohlcv(
                        symbol, 
                        timeframe, 
                        since=current_since, 
                        limit=limit
                    )
                    
                    if not ohlcv:
                        break
                    
                    all_candles.extend(ohlcv)
                    current_since = ohlcv[-1][0] + 1
                    
                    # Rate limiting
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
                    break
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(all_candles, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            df = df.drop_duplicates().sort_index()
            
            # ìºì‹œ ì €ì¥
            self.price_cache[cache_key] = (time.time(), df)
            
            # íŒŒì¼ë¡œ ì €ì¥
            filename = f"{self.data_dir}/raw/{symbol.replace('/', '_')}_{timeframe}_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}.csv"
            df.to_csv(filename)
            
            logger.info(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(df)} ìº”ë“¤")
            return df
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def get_multiple_symbols_data(
        self, 
        symbols: List[str], 
        timeframe: str = '1h',
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> Dict[str, pd.DataFrame]:
        """
        ì—¬ëŸ¬ ì‹¬ë³¼ì˜ ë°ì´í„° ë™ì‹œ ë‹¤ìš´ë¡œë“œ
        
        Args:
            symbols: ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
            timeframe: ì‹œê°„í”„ë ˆì„
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            
        Returns:
            Dict[str, DataFrame]: ì‹¬ë³¼ë³„ ë°ì´í„°
        """
        async def download_all():
            tasks = []
            for symbol in symbols:
                task = self.download_historical_data(symbol, timeframe, start_date, end_date)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            data_dict = {}
            for symbol, result in zip(symbols, results):
                if isinstance(result, Exception):
                    logger.error(f"ì‹¬ë³¼ {symbol} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result}")
                    data_dict[symbol] = pd.DataFrame()
                else:
                    data_dict[symbol] = result
            
            return data_dict
        
        return asyncio.run(download_all())
    
    def add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
        
        Args:
            df: OHLCV ë°ì´í„°
            
        Returns:
            DataFrame: ê¸°ìˆ ì  ì§€í‘œê°€ ì¶”ê°€ëœ ë°ì´í„°
        """
        try:
            # ì´ë™í‰ê· ì„ 
            df['SMA_20'] = df['close'].rolling(window=20).mean()
            df['SMA_50'] = df['close'].rolling(window=50).mean()
            df['SMA_200'] = df['close'].rolling(window=200).mean()
            
            # ì§€ìˆ˜ì´ë™í‰ê· ì„ 
            df['EMA_12'] = df['close'].ewm(span=12).mean()
            df['EMA_26'] = df['close'].ewm(span=26).mean()
            
            # RSI
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            df['RSI'] = 100 - (100 / (1 + rs))
            
            # MACD
            df['MACD'] = df['EMA_12'] - df['EMA_26']
            df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
            df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
            
            # ë³¼ë¦°ì € ë°´ë“œ
            df['BB_Middle'] = df['close'].rolling(window=20).mean()
            bb_std = df['close'].rolling(window=20).std()
            df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)
            df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)
            
            # ATR (Average True Range)
            high_low = df['high'] - df['low']
            high_close = np.abs(df['high'] - df['close'].shift())
            low_close = np.abs(df['low'] - df['close'].shift())
            true_range = np.maximum(high_low, np.maximum(high_close, low_close))
            df['ATR'] = true_range.rolling(window=14).mean()
            
            # ê±°ë˜ëŸ‰ ì§€í‘œ
            df['Volume_SMA'] = df['volume'].rolling(window=20).mean()
            df['Volume_Ratio'] = df['volume'] / df['Volume_SMA']
            
            # ê°€ê²© ë³€í™”ìœ¨
            df['Price_Change'] = df['close'].pct_change()
            df['Price_Change_5'] = df['close'].pct_change(5)
            df['Price_Change_10'] = df['close'].pct_change(10)
            
            # ë³€ë™ì„±
            df['Volatility'] = df['Price_Change'].rolling(window=20).std()
            
            logger.info("ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ ì™„ë£Œ")
            return df
            
        except Exception as e:
            logger.error(f"ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return df
    
    def save_processed_data(self, df: pd.DataFrame, symbol: str, timeframe: str):
        """
        ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        
        Args:
            df: ì²˜ë¦¬ëœ ë°ì´í„°
            symbol: ì‹¬ë³¼
            timeframe: ì‹œê°„í”„ë ˆì„
        """
        try:
            filename = f"{self.data_dir}/processed/{symbol.replace('/', '_')}_{timeframe}_processed.csv"
            df.to_csv(filename)
            logger.info(f"ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥: {filename}")
        except Exception as e:
            logger.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_processed_data(self, symbol: str, timeframe: str) -> pd.DataFrame:
        """
        ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
        
        Args:
            symbol: ì‹¬ë³¼
            timeframe: ì‹œê°„í”„ë ˆì„
            
        Returns:
            DataFrame: ì²˜ë¦¬ëœ ë°ì´í„°
        """
        try:
            filename = f"{self.data_dir}/processed/{symbol.replace('/', '_')}_{timeframe}_processed.csv"
            if os.path.exists(filename):
                df = pd.read_csv(filename, index_col=0, parse_dates=True)
                logger.info(f"ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ: {filename}")
                return df
            else:
                logger.warning(f"ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŒ: {filename}")
                return pd.DataFrame()
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def get_data_quality_report(self, df: pd.DataFrame) -> Dict:
        """
        ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±
        
        Args:
            df: ë°ì´í„°í”„ë ˆì„
            
        Returns:
            Dict: ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ
        """
        try:
            report = {
                'total_records': len(df),
                'date_range': {
                    'start': df.index.min().strftime('%Y-%m-%d %H:%M:%S'),
                    'end': df.index.max().strftime('%Y-%m-%d %H:%M:%S')
                },
                'missing_values': df.isnull().sum().to_dict(),
                'data_types': df.dtypes.to_dict(),
                'basic_stats': df.describe().to_dict(),
                'duplicates': df.duplicated().sum(),
                'completeness': (1 - df.isnull().sum() / len(df)).to_dict()
            }
            
            return report
            
        except Exception as e:
            logger.error(f"ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    async def get_all_usdt_futures_symbols(self) -> List[str]:
        """
        ëª¨ë“  USDT ì„ ë¬¼ ì‹¬ë³¼ ì¡°íšŒ
        
        Returns:
            List[str]: USDT ì„ ë¬¼ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ìºì‹œ í™•ì¸
            cache_key = "all_usdt_futures_symbols"
            if cache_key in self.symbol_cache:
                cache_time, symbols = self.symbol_cache[cache_key]
                if time.time() - cache_time < 3600:  # 1ì‹œê°„ ìºì‹œ
                    return symbols
            
            # ë°”ì´ë‚¸ìŠ¤ì—ì„œ ëª¨ë“  ë§ˆì¼“ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            markets = await self.exchange.load_markets()
            
            # USDT ì„ ë¬¼ ì‹¬ë³¼ë§Œ í•„í„°ë§
            usdt_futures = []
            for symbol, market in markets.items():
                if (market.get('type') == 'future' and 
                    market.get('quote') == 'USDT' and 
                    market.get('active', False)):
                    usdt_futures.append(symbol)
            
            # ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìƒìœ„ 100ê°œ)
            usdt_futures = sorted(usdt_futures)[:100]
            
            # ìºì‹œ ì €ì¥
            self.symbol_cache[cache_key] = (time.time(), usdt_futures)
            
            logger.info(f"USDT ì„ ë¬¼ ì‹¬ë³¼ ì¡°íšŒ ì™„ë£Œ: {len(usdt_futures)}ê°œ")
            return usdt_futures
            
        except Exception as e:
            logger.error(f"USDT ì„ ë¬¼ ì‹¬ë³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return [
                'BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'ADA/USDT', 'DOT/USDT',
                'SOL/USDT', 'AVAX/USDT', 'MATIC/USDT', 'LINK/USDT', 'UNI/USDT',
                'LTC/USDT', 'BCH/USDT', 'XRP/USDT', 'DOGE/USDT', 'SHIB/USDT',
                'ATOM/USDT', 'FTM/USDT', 'NEAR/USDT', 'ALGO/USDT', 'VET/USDT'
            ]
    
    async def scan_market_opportunities(
        self, 
        strategy_id: str, 
        timeframe: str = '1h',
        top_n: int = 20,
        log_callback: Optional[callable] = None
    ) -> List[Dict]:
        """
        ì‹œì¥ ì „ì²´ ìŠ¤ìº”ìœ¼ë¡œ ë§¤ë§¤ ê¸°íšŒ íƒìƒ‰
        
        Args:
            strategy_id: ì „ëµ ID
            timeframe: ì‹œê°„í”„ë ˆì„
            top_n: ìƒìœ„ Nê°œ ì‹¬ë³¼
            log_callback: ë¡œê·¸ ì½œë°± í•¨ìˆ˜
            
        Returns:
            List[Dict]: ë§¤ë§¤ ê¸°íšŒ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if log_callback:
                log_callback("ğŸ” ì‹œì¥ ì „ì²´ ìŠ¤ìº” ì‹œì‘", "system", 0)
            
            # ëª¨ë“  USDT ì„ ë¬¼ ì‹¬ë³¼ ì¡°íšŒ
            all_symbols = await self.get_all_usdt_futures_symbols()
            
            if log_callback:
                log_callback(f"ğŸ“Š ì´ {len(all_symbols)}ê°œ ì‹¬ë³¼ ìŠ¤ìº” ì¤‘...", "data", 10)
            
            # í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìµœê·¼ ë°ì´í„° ì¡°íšŒ
            end_date = datetime.now()
            start_date = end_date - timedelta(days=7)  # ìµœê·¼ 7ì¼
            
            opportunities = []
            
            # ê° ì‹¬ë³¼ì— ëŒ€í•´ ë§¤ë§¤ ê¸°íšŒ ë¶„ì„
            for i, symbol in enumerate(all_symbols[:top_n]):
                try:
                    progress = 10 + (i / top_n) * 80
                    if log_callback:
                        log_callback(f"  â””â”€ {symbol} ë¶„ì„ ì¤‘...", "analysis", progress)
                    
                    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                    data = await self.download_historical_data(
                        symbol, timeframe, start_date, end_date, limit=200
                    )
                    
                    if data.empty:
                        continue
                    
                    # ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
                    data = self.add_technical_indicators(data)
                    
                    # ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„
                    signal_strength = self.analyze_signal_strength(data, strategy_id)
                    
                    if signal_strength['score'] > 0.7:  # ê°•í•œ ì‹ í˜¸ë§Œ ì„ ë³„
                        opportunities.append({
                            'symbol': symbol,
                            'signal': signal_strength['signal'],
                            'score': signal_strength['score'],
                            'price': data['close'].iloc[-1],
                            'volume': data['volume'].iloc[-1],
                            'rsi': data['RSI'].iloc[-1],
                            'macd': data['MACD'].iloc[-1],
                            'volatility': data['Volatility'].iloc[-1],
                            'timestamp': datetime.now().isoformat()
                        })
                    
                    # Rate limiting
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"ì‹¬ë³¼ {symbol} ë¶„ì„ ì‹¤íŒ¨: {e}")
                    continue
            
            # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            opportunities.sort(key=lambda x: x['score'], reverse=True)
            
            if log_callback:
                log_callback(f"âœ… ì‹œì¥ ìŠ¤ìº” ì™„ë£Œ: {len(opportunities)}ê°œ ê¸°íšŒ ë°œê²¬", "system", 100)
            
            return opportunities
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ìŠ¤ìº” ì‹¤íŒ¨: {e}")
            if log_callback:
                log_callback(f"âŒ ì‹œì¥ ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}", "error", 0)
            return []
    
    def analyze_signal_strength(self, data: pd.DataFrame, strategy_id: str) -> Dict:
        """
        ë§¤ë§¤ ì‹ í˜¸ ê°•ë„ ë¶„ì„
        
        Args:
            data: ì‹œì¥ ë°ì´í„°
            strategy_id: ì „ëµ ID
            
        Returns:
            Dict: ì‹ í˜¸ ê°•ë„ ì •ë³´
        """
        try:
            if len(data) < 50:
                return {'signal': 'HOLD', 'score': 0.0}
            
            latest = data.iloc[-1]
            
            # ì „ëµë³„ ì‹ í˜¸ ë¶„ì„
            if strategy_id == 'triple_combo' or strategy_id == 'simple_triple_combo':
                # RSI + MACD + ë³¼ë¦°ì € ë°´ë“œ ì¡°í•©
                rsi = latest['RSI']
                macd = latest['MACD']
                macd_signal = latest['MACD_Signal']
                close = latest['close']
                bb_upper = latest['BB_Upper']
                bb_lower = latest['BB_Lower']
                
                buy_score = 0
                sell_score = 0
                
                # RSI ë¶„ì„
                if rsi < 30:
                    buy_score += 0.4
                elif rsi > 70:
                    sell_score += 0.4
                
                # MACD ë¶„ì„
                if macd > macd_signal:
                    buy_score += 0.3
                else:
                    sell_score += 0.3
                
                # ë³¼ë¦°ì € ë°´ë“œ ë¶„ì„
                if close <= bb_lower:
                    buy_score += 0.3
                elif close >= bb_upper:
                    sell_score += 0.3
                
                # ìµœì¢… ì‹ í˜¸ ê²°ì •
                if buy_score > sell_score and buy_score > 0.7:
                    return {'signal': 'BUY', 'score': buy_score}
                elif sell_score > buy_score and sell_score > 0.7:
                    return {'signal': 'SELL', 'score': sell_score}
                else:
                    return {'signal': 'HOLD', 'score': max(buy_score, sell_score)}
            
            elif strategy_id == 'rsi_strategy':
                # RSI ê¸°ë°˜ ì‹ í˜¸
                rsi = latest['RSI']
                if rsi < 30:
                    return {'signal': 'BUY', 'score': (30 - rsi) / 30}
                elif rsi > 70:
                    return {'signal': 'SELL', 'score': (rsi - 70) / 30}
                else:
                    return {'signal': 'HOLD', 'score': 0.0}
            
            else:
                # ê¸°ë³¸ ì‹ í˜¸ (ë‹¨ìˆœ ì´ë™í‰ê· )
                sma_20 = latest['SMA_20']
                sma_50 = latest['SMA_50']
                close = latest['close']
                
                if close > sma_20 > sma_50:
                    return {'signal': 'BUY', 'score': 0.8}
                elif close < sma_20 < sma_50:
                    return {'signal': 'SELL', 'score': 0.8}
                else:
                    return {'signal': 'HOLD', 'score': 0.0}
            
        except Exception as e:
            logger.error(f"ì‹ í˜¸ ê°•ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'signal': 'HOLD', 'score': 0.0}

class MLDataProcessor:
    """ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.feature_columns = []
        self.target_column = 'target'
        self.scaler = None
    
    def prepare_features(self, df: pd.DataFrame, prediction_horizon: int = 1) -> pd.DataFrame:
        """
        ML ëª¨ë¸ìš© í”¼ì²˜ ì¤€ë¹„
        
        Args:
            df: ì›ë³¸ ë°ì´í„°
            prediction_horizon: ì˜ˆì¸¡ ì§€í‰ì„  (ëª‡ ê¸°ê°„ í›„ ì˜ˆì¸¡í• ì§€)
            
        Returns:
            DataFrame: í”¼ì²˜ê°€ ì¤€ë¹„ëœ ë°ì´í„°
        """
        try:
            ml_df = df.copy()
            
            # ë¼ë²¨ ìƒì„± (ë‹¤ìŒ ê¸°ê°„ ê°€ê²© ìƒìŠ¹/í•˜ë½)
            ml_df['future_return'] = ml_df['close'].shift(-prediction_horizon) / ml_df['close'] - 1
            ml_df['target'] = (ml_df['future_return'] > 0).astype(int)
            
            # ê¸°ë³¸ í”¼ì²˜ë“¤
            features = [
                'open', 'high', 'low', 'close', 'volume',
                'SMA_20', 'SMA_50', 'SMA_200',
                'EMA_12', 'EMA_26',
                'RSI', 'MACD', 'MACD_Signal', 'MACD_Histogram',
                'BB_Upper', 'BB_Middle', 'BB_Lower',
                'ATR', 'Volume_Ratio',
                'Price_Change', 'Price_Change_5', 'Price_Change_10',
                'Volatility'
            ]
            
            # ì¶”ê°€ í”¼ì²˜ ìƒì„±
            ml_df['Price_Position'] = (ml_df['close'] - ml_df['BB_Lower']) / (ml_df['BB_Upper'] - ml_df['BB_Lower'])
            ml_df['RSI_Oversold'] = (ml_df['RSI'] < 30).astype(int)
            ml_df['RSI_Overbought'] = (ml_df['RSI'] > 70).astype(int)
            ml_df['Volume_Spike'] = (ml_df['Volume_Ratio'] > 2).astype(int)
            
            # ì‹œê°„ ê¸°ë°˜ í”¼ì²˜
            ml_df['Hour'] = ml_df.index.hour
            ml_df['DayOfWeek'] = ml_df.index.dayofweek
            ml_df['Month'] = ml_df.index.month
            
            # ìƒëŒ€ì  ìœ„ì¹˜ í”¼ì²˜
            ml_df['High_Low_Ratio'] = ml_df['high'] / ml_df['low']
            ml_df['Close_High_Ratio'] = ml_df['close'] / ml_df['high']
            ml_df['Close_Low_Ratio'] = ml_df['close'] / ml_df['low']
            
            features.extend([
                'Price_Position', 'RSI_Oversold', 'RSI_Overbought', 'Volume_Spike',
                'Hour', 'DayOfWeek', 'Month',
                'High_Low_Ratio', 'Close_High_Ratio', 'Close_Low_Ratio'
            ])
            
            self.feature_columns = features
            
            # NaN ê°’ ì²˜ë¦¬
            ml_df = ml_df.dropna()
            
            logger.info(f"ML í”¼ì²˜ ì¤€ë¹„ ì™„ë£Œ: {len(features)} í”¼ì²˜, {len(ml_df)} ìƒ˜í”Œ")
            return ml_df
            
        except Exception as e:
            logger.error(f"ML í”¼ì²˜ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def split_train_test(self, df: pd.DataFrame, test_size: float = 0.2) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
        
        Args:
            df: ë°ì´í„°í”„ë ˆì„
            test_size: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
            
        Returns:
            Tuple: (í›ˆë ¨ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ë°ì´í„°)
        """
        try:
            split_idx = int(len(df) * (1 - test_size))
            train_df = df.iloc[:split_idx]
            test_df = df.iloc[split_idx:]
            
            logger.info(f"ë°ì´í„° ë¶„í• : í›ˆë ¨ {len(train_df)}, í…ŒìŠ¤íŠ¸ {len(test_df)}")
            return train_df, test_df
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¶„í•  ì‹¤íŒ¨: {e}")
            return pd.DataFrame(), pd.DataFrame()
    
    def get_feature_importance(self, model, feature_names: List[str]) -> Dict[str, float]:
        """
        í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚°
        
        Args:
            model: í›ˆë ¨ëœ ëª¨ë¸
            feature_names: í”¼ì²˜ ì´ë¦„ë“¤
            
        Returns:
            Dict: í”¼ì²˜ ì¤‘ìš”ë„
        """
        try:
            if hasattr(model, 'feature_importances_'):
                importance = model.feature_importances_
                return dict(zip(feature_names, importance))
            else:
                return {}
        except Exception as e:
            logger.error(f"í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}