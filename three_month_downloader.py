#!/usr/bin/env python3
"""
3ê°œì›”ì¹˜ ë°ì´í„° ë‹¤ìš´ë¡œë” (ë¡œì»¬ìš©)
ë°±í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ 3ê°œì›” ë°ì´í„° ìˆ˜ì§‘
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import ccxt
import pandas as pd
from datetime import datetime, timedelta
import time
import logging
from pathlib import Path
from tqdm import tqdm
import json
from concurrent.futures import ThreadPoolExecutor, as_completed

class ThreeMonthDownloader:
    """3ê°œì›”ì¹˜ ë°ì´í„° ë‹¤ìš´ë¡œë”"""
    
    def __init__(self):
        self.data_path = Path("data/market_data")
        self.data_path.mkdir(parents=True, exist_ok=True)
        self.log_path = Path("logs")
        self.log_path.mkdir(parents=True, exist_ok=True)
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_path / f'three_month_download_{datetime.now().strftime("%Y%m%d")}.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ë°”ì´ë‚¸ìŠ¤ ê±°ë˜ì†Œ ì´ˆê¸°í™”
        self.exchange = ccxt.binance({
            'enableRateLimit': True,
            'timeout': 30000,
        })
        
        # 3ê°œì›”ì¹˜ ì„¤ì •
        self.timeframes = ['1m', '5m', '15m', '1h', '4h', '1d']
        self.symbols = ['BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'ADA/USDT', 'DOT/USDT']
        
        # 3ê°œì›” ê¸°ê°„ ì„¤ì • (2ì‹œê°„ ì „ê¹Œì§€ - ì•ˆì •ì ì¸ ë°ì´í„°)
        self.end_date = datetime.now() - timedelta(hours=2)
        self.start_date = self.end_date - timedelta(days=90)  # 3ê°œì›” = 90ì¼
        
        self.logger.info("ğŸ“… 3ê°œì›”ì¹˜ ë°ì´í„° ë‹¤ìš´ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ğŸ“Š ê¸°ê°„: {self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')}")
        self.logger.info(f"â° ì´ 90ì¼(3ê°œì›”)ì˜ ë°ì´í„° ìˆ˜ì§‘")
        self.logger.info(f"ğŸ¯ ì‹¬ë³¼: {self.symbols}")
        self.logger.info(f"ğŸ“ˆ ì‹œê°„í”„ë ˆì„: {self.timeframes}")

    def calculate_expected_records(self, timeframe: str) -> int:
        """ì˜ˆìƒ ë ˆì½”ë“œ ìˆ˜ ê³„ì‚°"""
        days = 90  # 3ê°œì›”
        
        records_per_day = {
            '1m': 1440,    # 1ì¼ = 1440ë¶„
            '5m': 288,     # 1ì¼ = 288ê°œ 5ë¶„ë´‰
            '15m': 96,     # 1ì¼ = 96ê°œ 15ë¶„ë´‰
            '1h': 24,      # 1ì¼ = 24ì‹œê°„
            '4h': 6,       # 1ì¼ = 6ê°œ 4ì‹œê°„ë´‰
            '1d': 1        # 1ì¼ = 1ê°œ ì¼ë´‰
        }
        
        return records_per_day.get(timeframe, 24) * days

    def test_api_connection(self):
        """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            self.logger.info("ğŸ”— ë°”ì´ë‚¸ìŠ¤ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            ticker = self.exchange.fetch_ticker('BTC/USDT')
            self.logger.info(f"âœ… API ì—°ê²° ì„±ê³µ! BTC í˜„ì¬ê°€: ${ticker['last']:,.2f}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ API ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            return False

    def download_single_timeframe(self, symbol: str, timeframe: str) -> dict:
        """ë‹¨ì¼ ì‹œê°„í”„ë ˆì„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        
        try:
            self.logger.info(f"ğŸ”„ {symbol} {timeframe} 3ê°œì›”ì¹˜ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            
            # ì˜ˆìƒ ë ˆì½”ë“œ ìˆ˜
            expected_records = self.calculate_expected_records(timeframe)
            self.logger.info(f"   ğŸ“Š ì˜ˆìƒ ë ˆì½”ë“œ: {expected_records:,}ê°œ")
            
            # íŒŒì¼ ê²½ë¡œ
            file_path = self.data_path / f"{symbol.replace('/', '_')}_{timeframe}.csv"
            
            # ì‹œê°„ ì„¤ì •
            since = int(self.start_date.timestamp() * 1000)
            end_time = int(self.end_date.timestamp() * 1000)
            
            all_data = []
            current_time = since
            
            # ì‹œê°„í”„ë ˆì„ë³„ ë°°ì¹˜ í¬ê¸° ìµœì í™”
            limit_map = {
                '1m': 1000,   # 1000ë¶„ = 16.7ì‹œê°„
                '5m': 1000,   # 5000ë¶„ = 83.3ì‹œê°„
                '15m': 1000,  # 15000ë¶„ = 250ì‹œê°„
                '1h': 1000,   # 1000ì‹œê°„ = 41.7ì¼
                '4h': 1000,   # 4000ì‹œê°„ = 166.7ì¼
                '1d': 1000    # 1000ì¼ = 2.7ë…„
            }
            
            limit = limit_map.get(timeframe, 1000)
            batch_count = 0
            total_records = 0
            
            # ì§„í–‰ ìƒí™© í‘œì‹œìš©
            progress_bar = tqdm(
                total=expected_records, 
                desc=f"{symbol} {timeframe}", 
                unit="records",
                leave=False
            )
            
            while current_time < end_time:
                try:
                    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    ohlcv = self.exchange.fetch_ohlcv(
                        symbol=symbol,
                        timeframe=timeframe,
                        since=current_time,
                        limit=limit
                    )
                    
                    if not ohlcv:
                        self.logger.warning(f"   âš ï¸ {symbol} {timeframe} ë” ì´ìƒ ë°ì´í„° ì—†ìŒ")
                        break
                    
                    # ë°ì´í„° ì¶”ê°€
                    all_data.extend(ohlcv)
                    batch_count += 1
                    total_records += len(ohlcv)
                    
                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    progress_bar.update(len(ohlcv))
                    
                    # ë‹¤ìŒ ì‹œì‘ ì‹œê°„ ê³„ì‚°
                    last_timestamp = ohlcv[-1][0]
                    current_time = last_timestamp + self._get_timeframe_ms(timeframe)
                    
                    # ì¤‘ê°„ ì§„í–‰ ìƒí™© ë¡œê·¸ (10ë°°ì¹˜ë§ˆë‹¤)
                    if batch_count % 10 == 0:
                        last_time = datetime.fromtimestamp(last_timestamp / 1000)
                        progress_percent = (total_records / expected_records * 100) if expected_records > 0 else 0
                        self.logger.info(f"   ğŸ“Š {symbol} {timeframe}: {total_records:,}/{expected_records:,} ({progress_percent:.1f}%), í˜„ì¬ {last_time.strftime('%Y-%m-%d')}")
                    
                    # API ì œí•œ ë°©ì§€
                    time.sleep(self.exchange.rateLimit / 1000)
                    
                    # ìš”ì²­í•œ ê¸°ê°„ì„ ë²—ì–´ë‚˜ë©´ ì¤‘ë‹¨
                    if last_timestamp >= end_time:
                        break
                        
                except Exception as e:
                    self.logger.error(f"   âŒ {symbol} {timeframe} ë°°ì¹˜ {batch_count} ì˜¤ë¥˜: {str(e)}")
                    time.sleep(5)  # ì˜¤ë¥˜ ì‹œ ëŒ€ê¸°
                    continue
            
            progress_bar.close()
            
            if not all_data:
                return {'symbol': symbol, 'timeframe': timeframe, 'success': False, 'records': 0, 'error': 'No data'}
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            df = df[~df.index.duplicated(keep='first')]
            df.sort_index(inplace=True)
            
            # ê¸°ê°„ í•„í„°ë§
            df = df[(df.index >= self.start_date) & (df.index <= self.end_date)]
            
            # íŒŒì¼ ì €ì¥
            df.to_csv(file_path)
            
            # ê²°ê³¼ ì •ë³´
            if not df.empty:
                first_time = df.index[0].strftime('%Y-%m-%d %H:%M')
                last_time = df.index[-1].strftime('%Y-%m-%d %H:%M')
                completion_rate = (len(df) / expected_records * 100) if expected_records > 0 else 0
                
                self.logger.info(f"âœ… {symbol} {timeframe} ì™„ë£Œ: {len(df):,}/{expected_records:,}ê°œ ({completion_rate:.1f}%)")
                self.logger.info(f"   ğŸ“… ì‹¤ì œ ë²”ìœ„: {first_time} ~ {last_time}")
                self.logger.info(f"   ğŸ’¾ ì €ì¥: {file_path}")
            
            return {
                'symbol': symbol, 
                'timeframe': timeframe, 
                'success': True, 
                'records': len(df),
                'expected': expected_records,
                'completion_rate': completion_rate,
                'file_path': str(file_path),
                'start_date': df.index[0].strftime('%Y-%m-%d') if not df.empty else None,
                'end_date': df.index[-1].strftime('%Y-%m-%d') if not df.empty else None
            }
            
        except Exception as e:
            self.logger.error(f"âŒ {symbol} {timeframe} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            import traceback
            self.logger.error(traceback.format_exc())
            return {'symbol': symbol, 'timeframe': timeframe, 'success': False, 'error': str(e)}

    def _get_timeframe_ms(self, timeframe: str) -> int:
        """ì‹œê°„í”„ë ˆì„ì„ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜"""
        timeframe_map = {
            '1m': 60 * 1000,
            '5m': 5 * 60 * 1000,
            '15m': 15 * 60 * 1000,
            '1h': 60 * 60 * 1000,
            '4h': 4 * 60 * 60 * 1000,
            '1d': 24 * 60 * 60 * 1000
        }
        return timeframe_map.get(timeframe, 60 * 1000)

    def download_all_data(self, parallel=True):
        """ëª¨ë“  3ê°œì›” ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        
        # API ì—°ê²° í…ŒìŠ¤íŠ¸
        if not self.test_api_connection():
            self.logger.error("âŒ API ì—°ê²° ì‹¤íŒ¨ë¡œ ë‹¤ìš´ë¡œë“œë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return []
        
        self.logger.info("ğŸš€ 3ê°œì›”ì¹˜ ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘!")
        start_time = datetime.now()
        
        # ë‹¤ìš´ë¡œë“œ ì‘ì—… ë¦¬ìŠ¤íŠ¸
        tasks = []
        for symbol in self.symbols:
            for timeframe in self.timeframes:
                tasks.append((symbol, timeframe))
        
        self.logger.info(f"ğŸ“‹ ì´ {len(tasks)}ê°œ ì‘ì—… (ì‹¬ë³¼ {len(self.symbols)}ê°œ Ã— ì‹œê°„í”„ë ˆì„ {len(self.timeframes)}ê°œ)")
        
        results = []
        
        if parallel:
            # ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ (ë¹ ë¦„, í•˜ì§€ë§Œ API ì œí•œ ì£¼ì˜)
            self.logger.info("âš¡ ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ëª¨ë“œ")
            with ThreadPoolExecutor(max_workers=3) as executor:  # 3ê°œ ë™ì‹œ ì‹¤í–‰
                future_to_task = {
                    executor.submit(self.download_single_timeframe, symbol, timeframe): (symbol, timeframe)
                    for symbol, timeframe in tasks
                }
                
                with tqdm(total=len(tasks), desc="3ê°œì›” ë°ì´í„° ë‹¤ìš´ë¡œë“œ", ncols=120) as pbar:
                    for future in as_completed(future_to_task):
                        symbol, timeframe = future_to_task[future]
                        try:
                            result = future.result()
                            results.append(result)
                            
                            if result['success']:
                                pbar.set_postfix_str(f"âœ… {symbol} {timeframe} ({result['records']:,} records)")
                            else:
                                pbar.set_postfix_str(f"âŒ {symbol} {timeframe}")
                                
                        except Exception as e:
                            self.logger.error(f"ì‘ì—… ì˜ˆì™¸ {symbol} {timeframe}: {str(e)}")
                            results.append({
                                'symbol': symbol, 
                                'timeframe': timeframe, 
                                'success': False, 
                                'error': str(e)
                            })
                        
                        pbar.update(1)
        else:
            # ìˆœì°¨ ë‹¤ìš´ë¡œë“œ (ì•ˆì •ì )
            self.logger.info("ğŸ”„ ìˆœì°¨ ë‹¤ìš´ë¡œë“œ ëª¨ë“œ")
            with tqdm(total=len(tasks), desc="3ê°œì›” ë°ì´í„° ë‹¤ìš´ë¡œë“œ", ncols=120) as pbar:
                for symbol, timeframe in tasks:
                    result = self.download_single_timeframe(symbol, timeframe)
                    results.append(result)
                    
                    if result['success']:
                        pbar.set_postfix_str(f"âœ… {symbol} {timeframe} ({result['records']:,} records)")
                    else:
                        pbar.set_postfix_str(f"âŒ {symbol} {timeframe}")
                    
                    pbar.update(1)
                    time.sleep(1)  # ì•ˆì „ ê°„ê²©
        
        # ê²°ê³¼ ìš”ì•½
        end_time = datetime.now()
        elapsed = end_time - start_time
        
        successful = [r for r in results if r['success']]
        failed = [r for r in results if not r['success']]
        
        self.logger.info("ğŸ‰ 3ê°œì›” ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        self.logger.info(f"â±ï¸ ì†Œìš”ì‹œê°„: {elapsed}")
        self.logger.info(f"âœ… ì„±ê³µ: {len(successful)}ê°œ")
        self.logger.info(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
        
        # ì„±ê³µí•œ ë‹¤ìš´ë¡œë“œ ìƒì„¸ ì •ë³´
        total_records = sum(r['records'] for r in successful)
        total_expected = sum(r.get('expected', 0) for r in successful)
        overall_completion = (total_records / total_expected * 100) if total_expected > 0 else 0
        
        self.logger.info(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {total_records:,}/{total_expected:,}ê°œ ({overall_completion:.1f}%)")
        
        # ê²°ê³¼ ìƒì„¸ ì¶œë ¥
        print("\n" + "="*100)
        print("ğŸ“Š 3ê°œì›” ë°ì´í„° ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ìƒì„¸:")
        print("="*100)
        
        for result in results:
            if result['success']:
                status = "âœ…"
                info = f"{result['records']:,}/{result.get('expected', 0):,}ê°œ ({result.get('completion_rate', 0):.1f}%)"
                date_range = f"({result.get('start_date', '')} ~ {result.get('end_date', '')})"
            else:
                status = "âŒ"
                info = f"ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"
                date_range = ""
            
            print(f"{status} {result['symbol']:>10} {result['timeframe']:>4}: {info} {date_range}")
        
        # ì‹¤íŒ¨ ìš”ì•½
        if failed:
            print(f"\nâŒ ì‹¤íŒ¨í•œ {len(failed)}ê°œ ë‹¤ìš´ë¡œë“œ:")
            for result in failed:
                print(f"   - {result['symbol']} {result['timeframe']}: {result.get('error', 'Unknown')}")
        
        # ì„±ê³µë¥  ìš”ì•½
        success_rate = len(successful) / len(results) * 100
        print(f"\nğŸ“ˆ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({len(successful)}/{len(results)})")
        print("="*100)
        
        return results

def main():
    try:
        print("ğŸ“… 3ê°œì›”ì¹˜ ë°ì´í„° ë‹¤ìš´ë¡œë”")
        print("=" * 70)
        print("ğŸ¯ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ 3ê°œì›” ì™„ì „ ë°ì´í„° ìˆ˜ì§‘")
        print("=" * 70)
        
        # ë‹¤ìš´ë¡œë“œ ëª¨ë“œ ì„ íƒ
        print("\në‹¤ìš´ë¡œë“œ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ (ë¹ ë¦„, ê¶Œì¥)")
        print("2. ìˆœì°¨ ë‹¤ìš´ë¡œë“œ (ì•ˆì •ì )")
        
        mode_choice = input("\nì„ íƒ (1-2, ê¸°ë³¸ê°’ 1): ").strip()
        parallel_mode = mode_choice != '2'
        
        mode_name = "ë³‘ë ¬" if parallel_mode else "ìˆœì°¨"
        print(f"\nâš¡ {mode_name} ëª¨ë“œë¡œ 3ê°œì›” ë°ì´í„° ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        downloader = ThreeMonthDownloader()
        results = downloader.download_all_data(parallel=parallel_mode)
        
        successful_count = len([r for r in results if r['success']])
        total_records = sum(r['records'] for r in results if r['success'])
        
        print("\n" + "=" * 70)
        print("ğŸ‰ 3ê°œì›” ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ {total_records:,}ê°œ ë ˆì½”ë“œ ìˆ˜ì§‘ ì™„ë£Œ")
        print("ì´ì œ ì™„ì „í•œ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("=" * 70)
        
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 