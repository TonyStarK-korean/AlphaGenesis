"""
ë™ì  ML ê¸°ë°˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging
from dataclasses import dataclass
import pickle
import joblib
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

from core.data_manager import DataManager
from core.backtest_engine import RealBacktestEngine

logger = logging.getLogger(__name__)

@dataclass
class RiskMetrics:
    """ë¦¬ìŠ¤í¬ ì§€í‘œ"""
    volatility: float
    var_95: float  # 95% VaR
    max_drawdown: float
    sharpe_ratio: float
    beta: float
    correlation_market: float
    liquidity_score: float
    momentum_score: float

@dataclass
class RiskParameters:
    """ë¦¬ìŠ¤í¬ ê´€ë¦¬ íŒŒë¼ë¯¸í„°"""
    max_position_size: float
    stop_loss_pct: float
    take_profit_pct: float
    max_leverage: float
    max_correlation: float
    min_liquidity: float
    risk_score: float
    recommended_allocation: float

class DynamicRiskManager:
    """ë™ì  ML ê¸°ë°˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.data_manager = DataManager()
        self.backtest_engine = None
        
        # ML ëª¨ë¸ë“¤
        self.volatility_model = None
        self.drawdown_model = None
        self.return_model = None
        self.risk_model = None
        
        # ìŠ¤ì¼€ì¼ëŸ¬ë“¤
        self.feature_scaler = StandardScaler()
        self.target_scaler = StandardScaler()
        
        # ëª¨ë¸ ê²½ë¡œ
        self.model_dir = "ml/models/saved"
        os.makedirs(self.model_dir, exist_ok=True)
        
        # ê¸°ë³¸ ë¦¬ìŠ¤í¬ íŒŒë¼ë¯¸í„°
        self.base_risk_params = {
            'max_position_size': 0.1,  # í¬íŠ¸í´ë¦¬ì˜¤ì˜ 10%
            'stop_loss_pct': 0.05,     # 5% ì†ì ˆ
            'take_profit_pct': 0.15,   # 15% ìµì ˆ
            'max_leverage': 3.0,       # ìµœëŒ€ 3ë°°
            'max_correlation': 0.7,    # ìµœëŒ€ ìƒê´€ê´€ê³„ 70%
            'min_liquidity': 0.3       # ìµœì†Œ ìœ ë™ì„± ì ìˆ˜ 30%
        }
        
        # ì‹œì¥ ë°ì´í„° ìºì‹œ
        self.market_data_cache = {}
        self.last_update = {}
        
    def get_backtest_engine(self):
        """ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ ì§€ì—° ì´ˆê¸°í™”"""
        if self.backtest_engine is None:
            self.backtest_engine = RealBacktestEngine()
        return self.backtest_engine
    
    async def train_risk_models(self, lookback_days: int = 365) -> Dict[str, Any]:
        """ML ë¦¬ìŠ¤í¬ ëª¨ë¸ í›ˆë ¨"""
        logger.info("ğŸ¤– ML ë¦¬ìŠ¤í¬ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        training_results = {
            'models_trained': [],
            'performance_metrics': {},
            'feature_importance': {},
            'training_errors': []
        }
        
        try:
            # í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘
            training_data = await self._collect_training_data(lookback_days)
            
            if training_data.empty:
                raise ValueError("í›ˆë ¨ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            
            # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
            features, targets = self._engineer_features(training_data)
            
            # ëª¨ë¸ë³„ í›ˆë ¨
            models_config = {
                'volatility': {
                    'target': 'volatility',
                    'model_class': RandomForestRegressor,
                    'params': {'n_estimators': 100, 'random_state': 42}
                },
                'drawdown': {
                    'target': 'max_drawdown',
                    'model_class': GradientBoostingRegressor,
                    'params': {'n_estimators': 100, 'random_state': 42}
                },
                'return': {
                    'target': 'return_1d',
                    'model_class': RandomForestRegressor,
                    'params': {'n_estimators': 150, 'random_state': 42}
                },
                'risk': {
                    'target': 'risk_score',
                    'model_class': GradientBoostingRegressor,
                    'params': {'n_estimators': 120, 'random_state': 42}
                }
            }
            
            for model_name, config in models_config.items():
                try:
                    model, metrics = self._train_single_model(
                        features, targets[config['target']], 
                        config['model_class'], config['params']
                    )
                    
                    # ëª¨ë¸ ì €ì¥
                    setattr(self, f"{model_name}_model", model)
                    self._save_model(model, f"{model_name}_model.pkl")
                    
                    training_results['models_trained'].append(model_name)
                    training_results['performance_metrics'][model_name] = metrics
                    
                    # íŠ¹ì„± ì¤‘ìš”ë„
                    if hasattr(model, 'feature_importances_'):
                        training_results['feature_importance'][model_name] = dict(
                            zip(features.columns, model.feature_importances_)
                        )
                    
                    logger.info(f"âœ… {model_name} ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ (RÂ² Score: {metrics['r2_score']:.3f})")
                    
                except Exception as e:
                    error_msg = f"{model_name} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}"
                    logger.error(error_msg)
                    training_results['training_errors'].append(error_msg)
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
            self._save_scaler(self.feature_scaler, "feature_scaler.pkl")
            
            logger.info(f"ğŸ¯ ML ë¦¬ìŠ¤í¬ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ: {len(training_results['models_trained'])}ê°œ ëª¨ë¸")
            
        except Exception as e:
            error_msg = f"ML ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}"
            logger.error(error_msg)
            training_results['training_errors'].append(error_msg)
        
        return training_results
    
    async def _collect_training_data(self, lookback_days: int) -> pd.DataFrame:
        """í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘"""
        logger.info(f"ğŸ“Š ìµœê·¼ {lookback_days}ì¼ ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        # ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ì—ì„œ ì£¼ìš” ì‹¬ë³¼ë“¤ì— ëŒ€í•œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        engine = self.get_backtest_engine()
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=lookback_days)
        
        training_records = []
        
        # ì£¼ìš” ì‹¬ë³¼ë“¤
        symbols = ['BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'ADA/USDT', 'DOT/USDT']
        strategies = ['triple_combo', 'rsi_strategy']
        
        for symbol in symbols:
            for strategy in strategies:
                try:
                    # 30ì¼ ë‹¨ìœ„ë¡œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°±í…ŒìŠ¤íŠ¸
                    current_date = start_date
                    while current_date < end_date - timedelta(days=30):
                        window_end = current_date + timedelta(days=30)
                        
                        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                        result = await engine.run_backtest(
                            symbol=symbol,
                            strategy=strategy,
                            start_date=current_date.strftime('%Y-%m-%d'),
                            end_date=window_end.strftime('%Y-%m-%d'),
                            initial_capital=100000
                        )
                        
                        if result:
                            # ì‹œì¥ ë°ì´í„° ë¡œë“œ
                            market_data = self.data_manager.load_data(symbol, '1h')
                            window_data = market_data[
                                (market_data.index >= current_date) & 
                                (market_data.index <= window_end)
                            ]
                            
                            if not window_data.empty:
                                # íŠ¹ì„± ë° íƒ€ê²Ÿ ê³„ì‚°
                                record = self._calculate_training_features(
                                    window_data, result, symbol, strategy
                                )
                                training_records.append(record)
                        
                        current_date += timedelta(days=7)  # 7ì¼ì”© ì´ë™
                        
                except Exception as e:
                    logger.warning(f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ({symbol}, {strategy}): {e}")
        
        if training_records:
            training_df = pd.DataFrame(training_records)
            logger.info(f"âœ… í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(training_df)} ë ˆì½”ë“œ")
            return training_df
        else:
            logger.warning("í›ˆë ¨ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
    
    def _calculate_training_features(self, market_data: pd.DataFrame, backtest_result: Any, 
                                   symbol: str, strategy: str) -> Dict[str, float]:
        """í›ˆë ¨ìš© íŠ¹ì„± ê³„ì‚°"""
        close_prices = market_data['close']
        volumes = market_data['volume']
        
        # ê°€ê²© íŠ¹ì„±
        returns = close_prices.pct_change().dropna()
        volatility = returns.std() * np.sqrt(24)  # ì¼ì¼ ë³€ë™ì„±
        
        # ê¸°ìˆ ì  ì§€í‘œ
        rsi = self._calculate_rsi(close_prices, 14).iloc[-1]
        
        # ë³¼ë¥¨ íŠ¹ì„±
        avg_volume = volumes.mean()
        volume_trend = volumes.pct_change().mean()
        
        # ëª¨ë©˜í…€ íŠ¹ì„±
        momentum_5d = (close_prices.iloc[-1] / close_prices.iloc[-5] - 1) if len(close_prices) >= 5 else 0
        momentum_20d = (close_prices.iloc[-1] / close_prices.iloc[-20] - 1) if len(close_prices) >= 20 else 0
        
        # ë³€ë™ì„± íŠ¹ì„±
        price_range = (market_data['high'] - market_data['low']) / market_data['close']
        avg_price_range = price_range.mean()
        
        # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ íƒ€ê²Ÿ ë³€ìˆ˜ë“¤
        total_return = getattr(backtest_result, 'total_return', 0)
        max_drawdown = abs(getattr(backtest_result, 'max_drawdown', 0))
        sharpe_ratio = getattr(backtest_result, 'sharpe_ratio', 0)
        win_rate = getattr(backtest_result, 'win_rate', 0)
        
        # ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° (0-100)
        risk_score = self._calculate_risk_score(volatility, max_drawdown, sharpe_ratio)
        
        return {
            # íŠ¹ì„±ë“¤
            'volatility_feature': volatility,
            'rsi': rsi,
            'avg_volume': avg_volume,
            'volume_trend': volume_trend,
            'momentum_5d': momentum_5d,
            'momentum_20d': momentum_20d,
            'avg_price_range': avg_price_range,
            'is_btc': 1 if 'BTC' in symbol else 0,
            'is_eth': 1 if 'ETH' in symbol else 0,
            'is_triple_combo': 1 if strategy == 'triple_combo' else 0,
            
            # íƒ€ê²Ÿë“¤
            'volatility': volatility,
            'max_drawdown': max_drawdown,
            'return_1d': total_return / 30,  # ì¼ì¼ ìˆ˜ìµë¥  ê·¼ì‚¬ì¹˜
            'risk_score': risk_score,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': win_rate
        }
    
    def _calculate_risk_score(self, volatility: float, max_drawdown: float, sharpe_ratio: float) -> float:
        """ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° (0-100, ë‚®ì„ìˆ˜ë¡ ì•ˆì „)"""
        # ê° ìš”ì†Œë¥¼ 0-100 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
        vol_score = min(volatility * 1000, 100)  # ë³€ë™ì„±
        dd_score = min(max_drawdown * 100, 100)  # ìµœëŒ€ ì†ì‹¤
        sharpe_score = max(0, 50 - sharpe_ratio * 25)  # ìƒ¤í”„ ë¹„ìœ¨ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        
        # ê°€ì¤‘ í‰ê· 
        risk_score = (vol_score * 0.4 + dd_score * 0.4 + sharpe_score * 0.2)
        return min(max(risk_score, 0), 100)
    
    def _engineer_features(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
        feature_columns = [
            'volatility_feature', 'rsi', 'avg_volume', 'volume_trend',
            'momentum_5d', 'momentum_20d', 'avg_price_range',
            'is_btc', 'is_eth', 'is_triple_combo'
        ]
        
        target_columns = [
            'volatility', 'max_drawdown', 'return_1d', 'risk_score'
        ]
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        clean_data = data.dropna()
        
        features = clean_data[feature_columns]
        targets = clean_data[target_columns]
        
        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        features_scaled = pd.DataFrame(
            self.feature_scaler.fit_transform(features),
            columns=features.columns,
            index=features.index
        )
        
        return features_scaled, targets
    
    def _train_single_model(self, features: pd.DataFrame, target: pd.Series, 
                           model_class, params: Dict) -> Tuple[Any, Dict]:
        """ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨"""
        # ì‹œê³„ì—´ êµì°¨ ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=5)
        
        cv_scores = []
        best_model = None
        best_score = float('-inf')
        
        for train_idx, val_idx in tscv.split(features):
            X_train, X_val = features.iloc[train_idx], features.iloc[val_idx]
            y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]
            
            # ëª¨ë¸ í›ˆë ¨
            model = model_class(**params)
            model.fit(X_train, y_train)
            
            # ê²€ì¦
            y_pred = model.predict(X_val)
            score = r2_score(y_val, y_pred)
            cv_scores.append(score)
            
            if score > best_score:
                best_score = score
                best_model = model
        
        # ìµœì¢… ëª¨ë¸ ì „ì²´ ë°ì´í„°ë¡œ ì¬í›ˆë ¨
        final_model = model_class(**params)
        final_model.fit(features, target)
        
        # ì„±ëŠ¥ ì§€í‘œ
        y_pred_final = final_model.predict(features)
        
        metrics = {
            'r2_score': r2_score(target, y_pred_final),
            'mse': mean_squared_error(target, y_pred_final),
            'cv_scores': cv_scores,
            'cv_mean': np.mean(cv_scores),
            'cv_std': np.std(cv_scores)
        }
        
        return final_model, metrics
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """RSI ê³„ì‚°"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    async def assess_risk(self, market_data: pd.DataFrame, symbol: str) -> float:
        """ì‹¤ì‹œê°„ ë¦¬ìŠ¤í¬ í‰ê°€"""
        try:
            # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¦¬ìŠ¤í¬ ì ìˆ˜ ë°˜í™˜
            if not self.risk_model:
                self.load_models()
            
            if not self.risk_model:
                return 50.0  # ì¤‘ê°„ ë¦¬ìŠ¤í¬
            
            # íŠ¹ì„± ê³„ì‚°
            features = self._calculate_realtime_features(market_data, symbol)
            
            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            features_scaled = self.feature_scaler.transform([features])
            
            # ë¦¬ìŠ¤í¬ ì ìˆ˜ ì˜ˆì¸¡
            risk_score = self.risk_model.predict(features_scaled)[0]
            
            return max(0, min(100, risk_score))
            
        except Exception as e:
            logger.error(f"ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 50.0
    
    def _calculate_realtime_features(self, market_data: pd.DataFrame, symbol: str) -> List[float]:
        """ì‹¤ì‹œê°„ íŠ¹ì„± ê³„ì‚°"""
        close_prices = market_data['close']
        volumes = market_data['volume']
        
        # ê°€ê²© íŠ¹ì„±
        returns = close_prices.pct_change().dropna()
        volatility = returns.std() * np.sqrt(24) if len(returns) > 0 else 0
        
        # ê¸°ìˆ ì  ì§€í‘œ
        rsi = self._calculate_rsi(close_prices, 14).iloc[-1] if len(close_prices) >= 14 else 50
        
        # ë³¼ë¥¨ íŠ¹ì„±
        avg_volume = volumes.mean() if len(volumes) > 0 else 0
        volume_trend = volumes.pct_change().mean() if len(volumes) > 1 else 0
        
        # ëª¨ë©˜í…€ íŠ¹ì„±
        momentum_5d = (close_prices.iloc[-1] / close_prices.iloc[-5] - 1) if len(close_prices) >= 5 else 0
        momentum_20d = (close_prices.iloc[-1] / close_prices.iloc[-20] - 1) if len(close_prices) >= 20 else 0
        
        # ë³€ë™ì„± íŠ¹ì„±
        if 'high' in market_data.columns and 'low' in market_data.columns:
            price_range = (market_data['high'] - market_data['low']) / market_data['close']
            avg_price_range = price_range.mean()
        else:
            avg_price_range = 0
        
        # ì‹¬ë³¼ íŠ¹ì„±
        is_btc = 1 if 'BTC' in symbol else 0
        is_eth = 1 if 'ETH' in symbol else 0
        is_triple_combo = 1  # ê¸°ë³¸ê°’
        
        return [
            volatility, rsi, avg_volume, volume_trend,
            momentum_5d, momentum_20d, avg_price_range,
            is_btc, is_eth, is_triple_combo
        ]
    
    async def calculate_optimal_risk_params(self, symbol: str, 
                                          strategy: str) -> RiskParameters:
        """ìµœì  ë¦¬ìŠ¤í¬ íŒŒë¼ë¯¸í„° ê³„ì‚°"""
        try:
            # ì‹œì¥ ë°ì´í„° ë¡œë“œ
            market_data = self.data_manager.load_data(symbol, '1h')
            
            if market_data.empty:
                return self._get_default_risk_params()
            
            # ML ì˜ˆì¸¡
            risk_score = await self.assess_risk(market_data, symbol)
            
            # ë³€ë™ì„± ì˜ˆì¸¡
            predicted_volatility = self._predict_volatility(market_data, symbol)
            
            # ìµœëŒ€ ì†ì‹¤ ì˜ˆì¸¡
            predicted_drawdown = self._predict_drawdown(market_data, symbol)
            
            # ë¦¬ìŠ¤í¬ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •
            risk_factor = risk_score / 100.0
            volatility_factor = min(predicted_volatility / 0.3, 2.0)  # ê¸°ì¤€ ë³€ë™ì„± 30%
            
            # ë™ì  íŒŒë¼ë¯¸í„° ê³„ì‚°
            max_position_size = self.base_risk_params['max_position_size'] / (1 + risk_factor)
            stop_loss_pct = self.base_risk_params['stop_loss_pct'] * (1 + volatility_factor * 0.5)
            take_profit_pct = self.base_risk_params['take_profit_pct'] * (1 + volatility_factor * 0.3)
            max_leverage = self.base_risk_params['max_leverage'] / (1 + risk_factor * 0.5)
            
            # ê¶Œì¥ í• ë‹¹ ë¹„ì¤‘
            base_allocation = 0.2  # ê¸°ë³¸ 20%
            recommended_allocation = base_allocation * (1 - risk_factor * 0.5)
            
            return RiskParameters(
                max_position_size=round(max_position_size, 3),
                stop_loss_pct=round(stop_loss_pct, 3),
                take_profit_pct=round(take_profit_pct, 3),
                max_leverage=round(max_leverage, 1),
                max_correlation=self.base_risk_params['max_correlation'],
                min_liquidity=self.base_risk_params['min_liquidity'],
                risk_score=round(risk_score, 1),
                recommended_allocation=round(recommended_allocation, 3)
            )
            
        except Exception as e:
            logger.error(f"ë¦¬ìŠ¤í¬ íŒŒë¼ë¯¸í„° ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self._get_default_risk_params()
    
    def _predict_volatility(self, market_data: pd.DataFrame, symbol: str) -> float:
        """ë³€ë™ì„± ì˜ˆì¸¡"""
        try:
            if self.volatility_model:
                features = self._calculate_realtime_features(market_data, symbol)
                features_scaled = self.feature_scaler.transform([features])
                return max(0, self.volatility_model.predict(features_scaled)[0])
            else:
                # ê¸°ë³¸ ê³„ì‚°
                returns = market_data['close'].pct_change().dropna()
                return returns.std() * np.sqrt(24) if len(returns) > 0 else 0.3
        except:
            return 0.3
    
    def _predict_drawdown(self, market_data: pd.DataFrame, symbol: str) -> float:
        """ìµœëŒ€ ì†ì‹¤ ì˜ˆì¸¡"""
        try:
            if self.drawdown_model:
                features = self._calculate_realtime_features(market_data, symbol)
                features_scaled = self.feature_scaler.transform([features])
                return max(0, self.drawdown_model.predict(features_scaled)[0])
            else:
                # ê¸°ë³¸ ê³„ì‚° (ìµœê·¼ ì†ì‹¤ íŒ¨í„´ ë¶„ì„)
                returns = market_data['close'].pct_change().dropna()
                cumulative = (1 + returns).cumprod()
                rolling_max = cumulative.expanding().max()
                drawdown = (cumulative - rolling_max) / rolling_max
                return abs(drawdown.min()) if len(drawdown) > 0 else 0.1
        except:
            return 0.1
    
    def _get_default_risk_params(self) -> RiskParameters:
        """ê¸°ë³¸ ë¦¬ìŠ¤í¬ íŒŒë¼ë¯¸í„°"""
        return RiskParameters(
            max_position_size=self.base_risk_params['max_position_size'],
            stop_loss_pct=self.base_risk_params['stop_loss_pct'],
            take_profit_pct=self.base_risk_params['take_profit_pct'],
            max_leverage=self.base_risk_params['max_leverage'],
            max_correlation=self.base_risk_params['max_correlation'],
            min_liquidity=self.base_risk_params['min_liquidity'],
            risk_score=50.0,
            recommended_allocation=0.2
        )
    
    def _save_model(self, model, filename: str):
        """ëª¨ë¸ ì €ì¥"""
        try:
            filepath = os.path.join(self.model_dir, filename)
            joblib.dump(model, filepath)
            logger.info(f"ëª¨ë¸ ì €ì¥: {filepath}")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_scaler(self, scaler, filename: str):
        """ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥"""
        try:
            filepath = os.path.join(self.model_dir, filename)
            joblib.dump(scaler, filepath)
            logger.info(f"ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥: {filepath}")
        except Exception as e:
            logger.error(f"ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_models(self) -> bool:
        """ì €ì¥ëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        try:
            model_files = {
                'volatility_model': 'volatility_model.pkl',
                'drawdown_model': 'drawdown_model.pkl',
                'return_model': 'return_model.pkl',
                'risk_model': 'risk_model.pkl'
            }
            
            loaded_count = 0
            
            for attr_name, filename in model_files.items():
                filepath = os.path.join(self.model_dir, filename)
                if os.path.exists(filepath):
                    try:
                        model = joblib.load(filepath)
                        setattr(self, attr_name, model)
                        loaded_count += 1
                    except Exception as e:
                        logger.warning(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            scaler_path = os.path.join(self.model_dir, "feature_scaler.pkl")
            if os.path.exists(scaler_path):
                try:
                    self.feature_scaler = joblib.load(scaler_path)
                    logger.info("íŠ¹ì„± ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            logger.info(f"âœ… {loaded_count}ê°œ ML ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return loaded_count > 0
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False